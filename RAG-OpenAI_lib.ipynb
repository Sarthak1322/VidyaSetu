{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d75d0d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f4bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PROVIDER = \"openai\"\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "APP_VERSION = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0100f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manoj/anaconda3/envs/langchain_rag_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üöÄ STARTING PDF BOOK WORKFLOW with UNSTRUCTURED\n",
      "==================================================\n",
      "‚úÖ Processing book directory: 'kehs1dd'\n",
      "  üìñ Processing Chapter: 'kehs101' with unstructured...\n",
      "  üìñ Processing Chapter: 'kehs102' with unstructured...\n",
      "  üìñ Processing Chapter: 'kehs103' with unstructured...\n",
      "  üìñ Processing Chapter: 'kehs104' with unstructured...\n",
      "  üìñ Processing Chapter: 'kehs105' with unstructured...\n",
      "  üìñ Processing Chapter: 'kehs106' with unstructured...\n",
      "  üìñ Processing Chapter: 'kehs107' with unstructured...\n",
      "  üìñ Processing Chapter: 'kehs1ps' with unstructured...\n",
      "‚úÖ Source processing complete. Total documents created: 136\n",
      "‚ÑπÔ∏è No FAISS index found. Creating a new one at: faiss_index_from_unstructured\n",
      "‚úÖ New FAISS index created and saved.\n",
      "\n",
      "üîç Performing similarity search for query: 'What is the main theme?'\n",
      "   üìÑ Result 1: \"Second: when you read about the making of states and empires in Sec- tion II, you will see that the drama unfolds not only in Rome (Theme 2), that is in Europe, but in the Central Islamic states (Theme 4), and the land of the Mongols (Theme 3). These...\"\n",
      "      ‚ñ∂Ô∏è  Metadata: [Book: kehs1dd] [Chapter File: kehs1ps.pdf] [Heading: viii] [Type: NarrativeText]\n",
      "   üìÑ Result 2: \"Theme 4: The Three Orders___________________________ 86...\"\n",
      "      ‚ñ∂Ô∏è  Metadata: [Book: kehs1dd] [Chapter File: kehs1ps.pdf] [Heading: Section III CHANGING TRADITIONS] [Type: UncategorizedText]\n",
      "   üìÑ Result 3: \"Theme 1: Writing and City Life ________________________ 9...\"\n",
      "      ‚ñ∂Ô∏è  Metadata: [Book: kehs1dd] [Chapter File: kehs1ps.pdf] [Heading: Section I EARLY SOCIETIES] [Type: UncategorizedText]\n",
      "\n",
      "üîç Performing similarity search for query: 'Find a character description.'\n",
      "   üìÑ Result 1: \"Difficulty level...\"\n",
      "      ‚ñ∂Ô∏è  Metadata: [Book: kehs1dd] [Chapter File: kehs1ps.pdf] [Heading: same subject] [Type: ListItem]\n",
      "   üìÑ Result 2: \"Publication Team...\"\n",
      "      ‚ñ∂Ô∏è  Metadata: [Book: kehs1dd] [Chapter File: kehs1ps.pdf] [Heading: Publication Team] [Type: Title]\n",
      "   üìÑ Result 3: \"CONTENTS...\"\n",
      "      ‚ñ∂Ô∏è  Metadata: [Book: kehs1dd] [Chapter File: kehs1ps.pdf] [Heading: CONTENTS] [Type: Title]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from openai import OpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS, Chroma\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "\n",
    "def get_documents_from_source(source_path):\n",
    "    \"\"\"\n",
    "    Extracts text and metadata from a source path using the 'unstructured'\n",
    "    library. It can handle a single PDF file or a directory of PDFs.\n",
    "\n",
    "    Args:\n",
    "        source_path (str): The path to the PDF file or directory.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of LangChain Document objects with rich metadata.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(source_path):\n",
    "        print(f\"üõë Error: Source path not found at {source_path}\")\n",
    "        return []\n",
    "\n",
    "    all_docs = []\n",
    "    \n",
    "    # Determine which PDF files to process\n",
    "    pdf_files_to_process = []\n",
    "    book_title = \"Single Document\"\n",
    "\n",
    "    if os.path.isdir(source_path):\n",
    "        book_title = os.path.basename(source_path)\n",
    "        print(f\"‚úÖ Processing book directory: '{book_title}'\")\n",
    "        pdf_files_to_process = [os.path.join(source_path, f) for f in sorted(os.listdir(source_path)) if f.lower().endswith('.pdf')]\n",
    "    elif os.path.isfile(source_path) and source_path.lower().endswith('.pdf'):\n",
    "        print(f\"‚úÖ Processing single PDF file: {os.path.basename(source_path)}\")\n",
    "        pdf_files_to_process.append(source_path)\n",
    "    else:\n",
    "        print(f\"üõë Error: Path '{source_path}' is not a valid PDF file or directory.\")\n",
    "        return []\n",
    "\n",
    "    if not pdf_files_to_process:\n",
    "        print(f\"üõë Warning: No PDF files found to process in {source_path}\")\n",
    "        return []\n",
    "\n",
    "    # Process each PDF file with 'unstructured'\n",
    "    for pdf_path in pdf_files_to_process:\n",
    "        chapter_title = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "        print(f\"  üìñ Processing Chapter: '{chapter_title}' with unstructured...\")\n",
    "        \n",
    "        try:\n",
    "            # The core of the new logic: partition_pdf\n",
    "            elements = partition_pdf(\n",
    "                filename=pdf_path,\n",
    "                # 'fast' is a good balance of speed and accuracy.\n",
    "                # Use 'hi_res' for more complex documents, which may require tesseract.\n",
    "                strategy=\"fast\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"üõë Error processing file {pdf_path} with unstructured: {e}\")\n",
    "            continue\n",
    "\n",
    "        current_heading = \"Introduction\" # Default for text before the first header\n",
    "        for el in elements:\n",
    "            # unstructured identifies titles and headers, which we use for chapter context\n",
    "            if el.category in (\"Title\", \"Header\", \"SubTitle\"):\n",
    "                current_heading = el.text.strip()\n",
    "            \n",
    "            # Create a Document for each element with detailed metadata\n",
    "            doc = Document(\n",
    "                page_content=el.text,\n",
    "                metadata={\n",
    "                    \"book_title\": book_title,\n",
    "                    \"chapter_file\": os.path.basename(pdf_path),\n",
    "                    \"heading_context\": current_heading,\n",
    "                    \"element_type\": el.category\n",
    "                }\n",
    "            )\n",
    "            all_docs.append(doc)\n",
    "\n",
    "    if not all_docs:\n",
    "        print(\"üõë Warning: No text could be extracted to create documents.\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Source processing complete. Total documents created: {len(all_docs)}\")\n",
    "    \n",
    "    return all_docs\n",
    "\n",
    "\n",
    "# --- FAISS Vector Store Functions ---\n",
    "\n",
    "def create_or_load_faiss_store(documents, embeddings, index_path=\"faiss_index\"):\n",
    "    if os.path.exists(index_path):\n",
    "        print(f\"‚úÖ Loading existing FAISS index from: {index_path}\")\n",
    "        vector_store = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    else:\n",
    "        print(f\"‚ÑπÔ∏è No FAISS index found. Creating a new one at: {index_path}\")\n",
    "        if not documents:\n",
    "            print(\"üõë Error: No documents provided to create a new FAISS store.\")\n",
    "            return None\n",
    "        vector_store = FAISS.from_documents(documents, embeddings)\n",
    "        vector_store.save_local(index_path)\n",
    "        print(f\"‚úÖ New FAISS index created and saved.\")\n",
    "    return vector_store\n",
    "\n",
    "# --- ChromaDB Vector Store Functions ---\n",
    "def create_or_load_chroma_store(documents, embeddings, persist_directory=\"chroma_db\"):\n",
    "    if os.path.exists(persist_directory):\n",
    "        print(f\"‚úÖ Loading existing ChromaDB from: {persist_directory}\")\n",
    "        vector_store = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
    "    else:\n",
    "        print(f\"‚ÑπÔ∏è No ChromaDB found. Creating a new one at: {persist_directory}\")\n",
    "        if not documents:\n",
    "            print(\"üõë Error: No documents provided to create a new ChromaDB store.\")\n",
    "            return None\n",
    "        vector_store = Chroma.from_documents(documents=documents, embedding=embeddings, persist_directory=persist_directory)\n",
    "        print(f\"‚úÖ New ChromaDB created and persisted.\")\n",
    "    return vector_store\n",
    "\n",
    "\n",
    "# --- Retrieval Function ---\n",
    "\n",
    "def perform_similarity_search(vector_store, query):\n",
    "    if not vector_store:\n",
    "        print(\"üõë Cannot perform search: Vector store is not available.\")\n",
    "        return []\n",
    "\n",
    "    print(f\"\\nüîç Performing similarity search for query: '{query}'\")\n",
    "    results = vector_store.similarity_search(query, k=3)\n",
    "    if not results:\n",
    "        print(\"   -> No results found.\")\n",
    "        return []\n",
    "        \n",
    "    for i, doc in enumerate(results):\n",
    "        content_snippet = \" \".join(doc.page_content.split())[:250] + \"...\"\n",
    "        print(f\"   üìÑ Result {i+1}: \\\"{content_snippet}\\\"\")\n",
    "        if doc.metadata:\n",
    "            book = doc.metadata.get('book_title', 'N/A')\n",
    "            chapter = doc.metadata.get('chapter_file', 'N/A')\n",
    "            heading = doc.metadata.get('heading_context', 'N/A')\n",
    "            el_type = doc.metadata.get('element_type', 'N/A')\n",
    "            print(f\"      ‚ñ∂Ô∏è  Metadata: [Book: {book}] [Chapter File: {chapter}] [Heading: {heading}] [Type: {el_type}]\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if not os.environ.get(\"OPENAI_API_KEY\") or os.environ.get(\"OPENAI_API_KEY\") == \"YOUR_API_KEY\":\n",
    "        print(\"üõë WARNING: Please set your OPENAI_API_KEY environment variable.\")\n",
    "    \n",
    "    embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üöÄ STARTING PDF BOOK WORKFLOW with UNSTRUCTURED\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # This path should point to your directory of PDFs\n",
    "    book_source_path = r\"/home/manoj/Project/RAG/kehs1dd\"\n",
    "    \n",
    "    # Dummy directory setup for first-time run\n",
    "    if not os.path.exists(book_source_path):\n",
    "        print(f\"‚ÑπÔ∏è Test directory not found. Creating '{book_source_path}' for demonstration.\")\n",
    "        os.makedirs(book_source_path)\n",
    "        # You MUST replace these with real PDFs for unstructured to work.\n",
    "        print(\"üõë Note: The created directory is empty. You MUST add real PDF files to it for processing.\")\n",
    "\n",
    "    book_faiss_path = \"faiss_index_from_unstructured\"\n",
    "    \n",
    "    # This now calls the unstructured-powered function\n",
    "    book_docs = get_documents_from_source(book_source_path)\n",
    "    \n",
    "    if book_docs:\n",
    "        faiss_store_from_book = create_or_load_faiss_store(book_docs, embedding_model, book_faiss_path)\n",
    "        perform_similarity_search(faiss_store_from_book, \"What is the main theme?\")\n",
    "        perform_similarity_search(faiss_store_from_book, \"Find a character description.\")\n",
    "    else:\n",
    "        print(\"\\nSkipping vector store creation because no documents were extracted.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
